{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# glm classifiers\n",
    "# sgdc (loss, classifier) - ('log', 'logistic regression'), ('hinge', 'linearsvm')\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "\n",
    "# naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# nearest neighbours\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# decision trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# datasets\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# linear algebra package\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# matplotlib broken for now\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def estimator_report(true_vals, predicted, estimator=\"Estimator\"):\n",
    "    \"\"\"\n",
    "        Helper function to format classfication report\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        true_vals : {np.array}\n",
    "            true class labels for test set\n",
    "        \n",
    "        predicted : {np.array}\n",
    "            estimator predicted values\n",
    "        \n",
    "        estimator : {string}\n",
    "            Estimator name - formatting purposes\n",
    "    \"\"\"\n",
    "    print \"Classification Report for %s\" % estimator\n",
    "    print classification_report(true_vals, predicted)\n",
    "    print \"\\n\"\n",
    "   \n",
    "    \n",
    "def whitening_transform(train_data):\n",
    "    \"\"\"\n",
    "        Function that determines whitenining transform\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        train_data : {np.array}\n",
    "            Class data in feature 1 and 2\n",
    "    \"\"\"\n",
    "    covar = np.cov(train_data.T, rowvar=True)\n",
    "    print \"Covariance Matrix: \"\n",
    "    print covar\n",
    "    eigenval,eigenvec = LA.eig(covar)\n",
    "    print \"Eigenvalues: \"\n",
    "    print eigenval\n",
    "    print \"Eigenvectors: \"\n",
    "    print eigenvec.T\n",
    "\n",
    "    # Compute orthornormal Whitening transform:\n",
    "    normal_eigenval = np.multiply(np.power(eigenval, -0.5), np.identity(2))\n",
    "    whitening = np.dot(normal_eigenval, eigenvec.T)\n",
    "    print \"Whitening:\"\n",
    "    print whitening\n",
    "    return whitening\n",
    "\n",
    "\n",
    "def compute_GED_distance(transform, mean, point):\n",
    "    \"\"\"\n",
    "        Computes transformed Euclidean distance\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        transform : {np.array}\n",
    "            2x2 array that contains the Whitening transform\n",
    "        mean : {np.array}\n",
    "            Sample mean (prototype) of dataset\n",
    "        point : {np.array}\n",
    "            Coordinates of point in feature space\n",
    "    \"\"\"\n",
    "    dist = np.dot(transform, (point - mean))\n",
    "    dist_T = np.dot((point - mean).T, transform.T)\n",
    "    dist = np.power(np.dot(dist_T, dist), 0.5)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def classify_point(whitening, point, prototypes):\n",
    "    \"\"\"\n",
    "        Computes transformed Euclidean distance\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        whitening : {np.array}\n",
    "            2x2 array that contains the Whitening transform\n",
    "        point : {np.array}\n",
    "            Coordinates of point in feature space\n",
    "        prototypes : {np.array}\n",
    "            Contains array of sample means (prototypes) of dataset\n",
    "    \"\"\"\n",
    "    min_dist = sys.maxint\n",
    "    clazz = 0\n",
    "    for idx, p in enumerate(prototypes):\n",
    "        dist = compute_GED_distance(whitening, p, point)\n",
    "        if dist < min_dist:\n",
    "            clazz = idx\n",
    "            min_dist = dist\n",
    "    return clazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=[data.feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[\"target\"] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# use numpy permutation to shuffle the data\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# features of interest\n",
    "foi = [\"petal length (cm)\", \"petal width (cm)\"]\n",
    "# foi = list(set(df.columns) - set([\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "estimators = {\"Logistic Regression\": SGDClassifier(loss=\"log\", penalty=\"l2\"),\n",
    "              \"Nearest Neighbours\": KNeighborsClassifier(15),\n",
    "              \"Naive Bayes\": GaussianNB(),\n",
    "              \"Random Forest\": RandomForestClassifier(n_estimators=100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = df[foi].values\n",
    "y = df[\"target\"].values\n",
    "X_train = X[:int(len(X)*0.7)] # retain 70% of data set for training\n",
    "X_test = X[int(len(X)*0.7):]\n",
    "y_train = y[:int(len(y)*0.7)]\n",
    "y_test = y[int(len(y)*0.7):]\n",
    "\n",
    "# Concatenate prior arrays for GED classifier\n",
    "Z = np.c_[X, y]\n",
    "Z_train = Z[:int(len(Z)*0.7)] # retain 70% of data set for training\n",
    "Z_test = Z[int(len(Z)*0.7):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Nearest Neighbours\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        14\n",
      "          1       1.00      0.94      0.97        16\n",
      "          2       0.94      1.00      0.97        15\n",
      "\n",
      "avg / total       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for Logistic Regression\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      1.00      0.97        14\n",
      "          1       0.90      0.56      0.69        16\n",
      "          2       0.70      0.93      0.80        15\n",
      "\n",
      "avg / total       0.84      0.82      0.81        45\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in estimators.iteritems():\n",
    "    # train\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # predict\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    estimator_report(y_test, y_pred, estimator=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Retrieve sample means (prototypes) from the 3 classes in the training data\n",
    "prototypes = []\n",
    "for i in xrange(0, 3):\n",
    "    prototypes.append(np.mean(X_train[y_train == i], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix: \n",
      "[[ 3.16635897  1.30030769]\n",
      " [ 1.30030769  0.57381319]]\n",
      "Eigenvalues: \n",
      "[ 3.70614804  0.03402412]\n",
      "Eigenvectors: \n",
      "[[ 0.92358193  0.38340112]\n",
      " [-0.38340112  0.92358193]]\n",
      "Whitening:\n",
      "[[ 0.47974896  0.19915536]\n",
      " [-2.07854726  5.00705029]]\n"
     ]
    }
   ],
   "source": [
    "# Create Whitening (orthonormal covariance) transform from training data\n",
    "whitening = whitening_transform(X_train)\n",
    "X_train_whitened = np.dot(whitening, X_train.T).T\n",
    "\n",
    "# Apply Whitening transform on testing data for plotting\n",
    "X_test_whitened = np.dot(whitening, X_test.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:\n",
      "0.04\n"
     ]
    }
   ],
   "source": [
    "# Classify test points\n",
    "error = 0\n",
    "X_new_classes = []\n",
    "for point in Z_test:\n",
    "    coords = point[:2]\n",
    "    new_class = classify_point(whitening, coords, prototypes)\n",
    "    if point[2] != new_class:\n",
    "        error += 1\n",
    "    X_new_classes.append(new_class)\n",
    "\n",
    "print \"ERROR:\"\n",
    "print error / 150.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the non-whitened and whitened data points\n",
    "plt.figure(1)\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X_test[:, 0].min() - 1, X_test[:, 0].max() + 1\n",
    "y_min, y_max = X_test[:, 1].min() - 1, X_test[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Iris Test Data')\n",
    "\n",
    "x_min_whitened, x_max_whitened = X_test_whitened[:, 0].min() - 1, X_test_whitened[:, 0].max() + 1\n",
    "y_min_whitened, y_max_whitened = X_test_whitened[:, 1].min() - 1, X_test_whitened[:, 1].max() + 1\n",
    "xx_whitened, yy_whitened = np.meshgrid(np.arange(x_min_whitened, x_max_whitened, h),\n",
    "                     np.arange(y_min_whitened, y_max_whitened, h))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(X_test_whitened[:, 0], X_test_whitened[:, 1], c=y_test, cmap=plt.cm.coolwarm)\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "plt.xlim(xx_whitened.min(), xx_whitened.max())\n",
    "plt.ylim(yy_whitened.min(), yy_whitened.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('Whitened Iris Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
